\documentclass[11pt]{article}

%  USE PACKAGES  ---------------------- 
\usepackage[margin=0.75in,vmargin=1in]{geometry}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath,amsthm,amsfonts}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{enumerate}
\usepackage{mathtools}
\usepackage{hyperref,color}
\usepackage{enumitem,amssymb}
\usepackage{indentfirst}
\usepackage{hyperref}
\usepackage{graphicx}
\newlist{todolist}{itemize}{4}
\setlist[todolist]{label=$\square$}
\usepackage{pifont}
\usepackage{xcolor}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcommand{\done}{\rlap{$\square$}{\raisebox{2pt}{\large\hspace{1pt}\cmark}}%
\hspace{-2.5pt}}
\newcommand{\HREF}[2]{\href{#1}{#2}}
%  -------------------------------------------- 

%  HEADER AND FOOTER (DO NOT EDIT) ----------------------
\newcommand{\problemnumber}{0}
\pagestyle{fancy}
\fancyhead{}
\fancyhead[L]{\textbf{IE332 Project 2 Report}}
\newcommand{\newquestion}[1]{
\clearpage % page break and flush floats
\renewcommand{\problemnumber}{#1} % set problem number for header
\phantom{}  % Put something on the page so it shows
}
\fancyfoot[L]{IE 332}
\fancyfoot[C]{Project Report 2}
\fancyfoot[R]{Page \thepage}
\renewcommand{\footrulewidth}{0.4pt}

%  --------------------------------------------


%  COVER SHEET (WRITE YOUR FULL NAME(S) WHERE INDICATED!) ----------------------
\newcommand{\addcoversheet}{
\clearpage
\thispagestyle{empty}
\vspace*{0.5in}

\begin{center}
\Huge{{\bf IE332 Group 5 Project Report 2}} % <-- replace with correct assignment #

Due: April 28th, 11:59pm EST % <-- replace with correct due date and time
\end{center}

\vspace{0.2in}

\noindent {\em ``As a Boilermaker pursuing academic excellence, I pledge to be honest and true in all that I do.
Accountable together - we are Purdue.''}

\vspace{0.3in}

\begin{table}[h!]
  \begin{center}
    \label{tab:table1}
    \begin{tabular}{c|ccccccc|c|c}
      Student & Alg 1 & Alg 2 & Alg 3 & Alg 4 & Alg 5 & Main Alg & Report & Overall & DIFF\\
      \hline
      Henry Liu & 25 & 25 & 25 & 25 & 25 & 25 & 25 & 175 & 0\\
      Keegan Kell & 25 & 25 & 25 & 25 & 25 & 25 & 25 & 175 & 0\\
      Francis Stolorz & 25 & 25 & 25 & 25 & 25 & 25 & 25 & 175 & 0\\
      Jair Zenil Martinez & 25 & 25 & 25 & 25 & 25 & 25 & 25 & 175 & 0\\
      \hline
      St Dev & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0
    \end{tabular}
  \end{center}
\end{table}

\vspace{0.2in}

\noindent Date: \today.
}

\begin{document}

\addcoversheet
\addtodo

% BEGIN YOUR ASSIGNMENT HERE:
\newpage
\tableofcontents

\newpage
\section{Description}
This project involves training a voting-based optimization algorithm to perform adversarial attacks on a binary image classifier. The goal is to trick the classifier by changing a specific number of pixels in the image. The classifier, which has 100\% accuracy on a set of training data, accepts an image and attempts to identify it as either X or Y based on the preponderance of the evidence. An optimizer must provide weights to the algorithms before selecting them based on their projected performance in order to attack the classifier. The majority votes of the algorithms determine the compound classifier's output.\\

Five distinct machine learning and/or optimization techniques must be employed independently to attempt to trick the classifier in order to accomplish this project successfully. The algorithms will be placed inside of another algorithm, which must provide them weights based on how well they should perform given the image. The optimizer must then decide which pixels to use out of the set that the algorithms have chosen to alter. A picture and a scalar (that informs the algorithm of the expected budget in terms of the ratio of the image size) will both be inputs to the adversarial function. The group as a whole will pick five sub-algorithms, each one being assigned to each individual group member.\\

The number of successfully deceived photographs at a specific budget level will be used to evaluate the performance of the algorithms. The smaller the budget, the more valuable each successfully fooled image is, and this scales with the size of the image. The project's success criteria are that the model must successfully fool the classifier with exactly B (the pixel budget) pixels changed in the image, and this must be done in less than 10 seconds per image. The model must be able to fool the classifier with a budget of P/100 for at least one image, where P is the number of pixels in the image.\\

To complete this project, a complete justification of the rationale for selecting each of the five machine learning algorithms will be provided. This justification will also cover how they were trained and how the optimizer allocates the votes. Finally, the justification should explain why such an approach should work. All code, notes, documentation, etc. must be tracked using Git and Github for verification of the effort contributed by each team member. 

\newpage
\section{Problem Being Addressed}


\newpage
\section{Solution to the Problem}

\newpage
\noindent\section{Selection of Algorithms}
As a group, we have selected five sub-algorithms that we believe will work best for our overall algorithm. These sub-algorithms were carefully selected, and each one was assigned to a group member. Below is a description of each algorithm, how it works, and the process of each algorithm.
\subsection{Fast Gradient Sign Method}
The Fast Gradient Sign Method is a technique used in adversarial machine learning to generate adversarial examples that can fool a machine learning model. The FGSM algorithm takes advantage of the gradient information of the loss function with respect to the input data to generate adversarial examples.\\

To generate an adversarial example using FGSM, the algorithm first computes the gradient of the loss function with respect to the input data. Then, it uses the sign of the gradient to generate a perturbation vector that is added to the original input to create the adversarial example. The magnitude of the perturbation vector is controlled by a hyperparameter epsilon, which determines how far the perturbation can deviate from the original input.\\

The resulting adversarial example is designed to be as close to the original input as possible while still causing the model to make a misclassification. The goal of this attack is to expose the model's weaknesses and vulnerabilities, and to evaluate its robustness and security against potential real-world attacks. The FGSM algorithm is simple and efficient, and can be applied to various types of machine learning models, including neural networks, decision trees, and support vector machines.\\

We chose the FGSM method because it is fast, computationally efficient, and easy to implement, making it a suitable choice for adversarial attacks. It has been shown to be effective against a wide range of deep learning models, including image classifiers. FGSM can successfully fool binary image classifiers with a relatively small number of perturbations, even with a low pixel budget. Additionally, FGSM can be used to generate a large number of adversarial examples quickly, which is important when optimizing the weights of the different sub-algorithms.
\subsection{Basic Iterative Method}
\subsection{Deep Fool}
\subsection{Carlini-Wagner}
\subsection{Projected Gradient Descent}

\newpage
\section{Correctness of Proofs}

\newpage
\section{Complexity Analysis}

\clearpage
\section{References}

\newpage
\section{Appendix}

\subsection{Testing/Correctness/Verification}

\newpage\subsection{Runtime Complexity and Walltime}

\newpage\subsection{Performance}

\newpage\subsection{Final Algorithm Selection Justification}

\end{document}
